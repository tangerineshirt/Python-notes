{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4135fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b54cd0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time (s)</th>\n",
       "      <th>HR (BPM)</th>\n",
       "      <th>RESP (BPM)</th>\n",
       "      <th>SpO2 (%)</th>\n",
       "      <th>TEMP (*C)</th>\n",
       "      <th>OUTPUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>36.2</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>36.2</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time (s)   HR (BPM)   RESP (BPM)   SpO2 (%) TEMP (*C)  OUTPUT\n",
       "0      94.0       21.0         97.0       36.2    Normal     NaN\n",
       "1      94.0       25.0         97.0       36.2    Normal     NaN\n",
       "2     101.0       25.0         93.0       38.0  Abnormal     NaN\n",
       "3      55.0       11.0        100.0       35.0  Abnormal     NaN\n",
       "4      93.0       26.0         95.0       37.0    Normal     NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Human_vital_signs_R.csv\")\n",
    "\n",
    "df = df.drop(columns=[\"ID\", \"Bruh\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba98ee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"OUTPUT\"])\n",
    "Y = df[\"OUTPUT\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cc80652",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Abnormal'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_23388\\1056003048.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      2\u001b[39m     StandardScaler(),\n\u001b[32m      3\u001b[39m     DecisionTreeClassifier()\n\u001b[32m      4\u001b[39m )\n\u001b[32m      5\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m pipe.fit(X_train, Y_train)\n",
      "\u001b[32md:\\CCCodes\\.venv\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1361\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m                 )\n\u001b[32m   1364\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32md:\\CCCodes\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    651\u001b[39m                 \u001b[33m\"`sklearn.set_config(enable_metadata_routing=True)`.\"\u001b[39m\n\u001b[32m    652\u001b[39m             )\n\u001b[32m    653\u001b[39m \n\u001b[32m    654\u001b[39m         routed_params = self._check_method_params(method=\u001b[33m\"fit\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m         Xt = self._fit(X, y, routed_params, raw_params=params)\n\u001b[32m    656\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"Pipeline\"\u001b[39m, self._log_message(len(self.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    657\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m self._final_estimator != \u001b[33m\"passthrough\"\u001b[39m:\n\u001b[32m    658\u001b[39m                 last_step_params = self._get_metadata_for_step(\n",
      "\u001b[32md:\\CCCodes\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    585\u001b[39m                 step_params=routed_params[name],\n\u001b[32m    586\u001b[39m                 all_params=raw_params,\n\u001b[32m    587\u001b[39m             )\n\u001b[32m    588\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[32m    590\u001b[39m                 cloned_transformer,\n\u001b[32m    591\u001b[39m                 X,\n\u001b[32m    592\u001b[39m                 y,\n",
      "\u001b[32md:\\CCCodes\\.venv\\Lib\\site-packages\\joblib\\memory.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __call__(self, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.func(*args, **kwargs)\n",
      "\u001b[32md:\\CCCodes\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1536\u001b[39m     \"\"\"\n\u001b[32m   1537\u001b[39m     params = params \u001b[38;5;28;01mor\u001b[39;00m {}\n\u001b[32m   1538\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1539\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m hasattr(transformer, \u001b[33m\"fit_transform\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m             res = transformer.fit_transform(X, y, **params.get(\u001b[33m\"fit_transform\"\u001b[39m, {}))\n\u001b[32m   1541\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1542\u001b[39m             res = transformer.fit(X, y, **params.get(\"fit\", {})).transform(\n\u001b[32m   1543\u001b[39m                 X, **params.get(\u001b[33m\"transform\"\u001b[39m, {})\n",
      "\u001b[32md:\\CCCodes\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m     @wraps(f)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m wrapped(self, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         data_to_wrap = f(self, X, *args, **kwargs)\n\u001b[32m    317\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(data_to_wrap, tuple):\n\u001b[32m    318\u001b[39m             \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m             return_tuple = (\n",
      "\u001b[32md:\\CCCodes\\.venv\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    893\u001b[39m             \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m    894\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, **fit_params).transform(X)\n\u001b[32m    895\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m             \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[32md:\\CCCodes\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    903\u001b[39m             Fitted scaler.\n\u001b[32m    904\u001b[39m         \"\"\"\n\u001b[32m    905\u001b[39m         \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    906\u001b[39m         self._reset()\n\u001b[32m--> \u001b[39m\u001b[32m907\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.partial_fit(X, y, sample_weight)\n",
      "\u001b[32md:\\CCCodes\\.venv\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1361\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m                 )\n\u001b[32m   1364\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32md:\\CCCodes\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    939\u001b[39m         self : object\n\u001b[32m    940\u001b[39m             Fitted scaler.\n\u001b[32m    941\u001b[39m         \"\"\"\n\u001b[32m    942\u001b[39m         first_call = \u001b[38;5;28;01mnot\u001b[39;00m hasattr(self, \u001b[33m\"n_samples_seen_\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m         X = validate_data(\n\u001b[32m    944\u001b[39m             self,\n\u001b[32m    945\u001b[39m             X,\n\u001b[32m    946\u001b[39m             accept_sparse=(\u001b[33m\"csr\"\u001b[39m, \u001b[33m\"csc\"\u001b[39m),\n",
      "\u001b[32md:\\CCCodes\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2950\u001b[39m             out = y\n\u001b[32m   2951\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2952\u001b[39m             out = X, y\n\u001b[32m   2953\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m         out = check_array(X, input_name=\u001b[33m\"X\"\u001b[39m, **check_params)\n\u001b[32m   2955\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m         out = _check_y(y, **check_params)\n\u001b[32m   2957\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32md:\\CCCodes\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) from complex_warning\n",
      "\u001b[32md:\\CCCodes\\.venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32md:\\CCCodes\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2164\u001b[39m             )\n\u001b[32m   2165\u001b[39m         values = self._values\n\u001b[32m   2166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2167\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2168\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2171\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Abnormal'"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    DecisionTreeClassifier()\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
